<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>PREDICTION ALGORITHM FOR BARBELL LIFTS THROUGH CLASSIFICATION MODELS:LOGISTIC REGRESSION AND LINEAR DISCRIMINANT ANALYSIS</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<h1>PREDICTION ALGORITHM FOR BARBELL LIFTS THROUGH CLASSIFICATION MODELS:LOGISTIC REGRESSION AND LINEAR DISCRIMINANT ANALYSIS</h1>

<h2>ABSTRACT</h2>

<p>These document present the algorithm for classify the ways of doing dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E) [1].</p>

<p>In the process was considered a linear discriminant analysis and logistic regression, the best model was the logistic regression with an accuracy of 73% in the test set. The approximate accuracy for predict the classes A,B,C,D and E are 87%,64%,67%,72% and 67%, respectively. </p>

<p>The correct sequence provided by the course practice machine learning,   for the twenty test is: &ldquo;B&rdquo; &ldquo;A&rdquo; &ldquo;B&rdquo; &ldquo;A&rdquo; &ldquo;A&rdquo; &ldquo;E&rdquo; &ldquo;D&rdquo; &ldquo;B&rdquo; &ldquo;A&rdquo; &ldquo;A&rdquo; &ldquo;B&rdquo; &ldquo;C&rdquo; &ldquo;B&rdquo; &ldquo;A&rdquo; &ldquo;E&rdquo; &ldquo;E&rdquo; &ldquo;A&rdquo; &ldquo;B&rdquo; &ldquo;B&rdquo; &ldquo;B&rdquo;, the result is obtained by a logistic regression model in two attempts.</p>

<h2>PREPROCESSING</h2>

<p>Before of build the model, is necessary preprocess the dataset obtained from <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>, the preprocess consist in the following steps:</p>

<ul>
<li>Open the file and extract the information  with the measures registered from the arms, belt,dumbbell and forearms.</li>
</ul>

<pre><code class="r">library(stringr) 
train=read.csv(file=&quot;pml-training.csv&quot;,header=TRUE)
  names_train&lt;-names(train)
  #Vector that contain the index for the information of arms,belt,dumbbell and forearms
  index&lt;-vector()

  # index for store the indexes 
  j&lt;-0
  for (i in 1:length(names_train)) {
      name&lt;-str_split(names_train[i],&quot;_&quot;)
     if((any(name[[1]]==&quot;forearm&quot;)|any(name[[1]]==&quot;arm&quot;)|any(name[[1]]==&quot;belt&quot;)|
           any(name[[1]]==&quot;dumbbell&quot;))&amp;(class(train[,i])==&quot;numeric&quot; |
                                              class(train[,i])==&quot;integer&quot;) ) 
       {j&lt;-j+1
       index[j]&lt;-i}}
</code></pre>

<ul>
<li>Divided the training dataset in the train and test sets, for these is considered a 50% of the data.</li>
</ul>

<pre><code class="r">library(caret) 
</code></pre>

<pre><code>## Loading required package: lattice
## Loading required package: ggplot2
</code></pre>

<pre><code class="r">set.seed(1)
  inTrain&lt;-createDataPartition(train$classe,p=0.5,list=FALSE)
  test&lt;-train[-inTrain,]
  train&lt;-train[inTrain,]
</code></pre>

<ul>
<li>Eliminate the predictors that not contain information for all the registers of the test and train set.</li>
</ul>

<pre><code class="r">  train2&lt;-train[,c(index)]
  #Eliminate the predictors with NA from the train set
  train2&lt;-train2[,!apply(apply(train2,2,is.na),2,any)]

  test2&lt;-test[,c(index)]
  #Eliminate the predictors with NA from the test set
  test2&lt;-test2[,!apply(apply(test2,2,is.na),2,any)]
</code></pre>

<p>-Create a dataframe with all the classes for train the model, the columns of the dataframe contain 0 and 1 for each response, for example if the value correspond with the class the value is 1,otherwise the value is 0.</p>

<pre><code class="r">  train_class&lt;-list()
  class&lt;-unique(test$classe)

  for (q in 1:length(class)){

  temp&lt;- as.character(train$classe)
  temp[temp!=class[q]]&lt;-0
  temp[temp==class[q]]&lt;-1

  train_class[[class[q]]]&lt;-as.numeric(temp)  
  }
  train_class&lt;-as.data.frame(train_class)
  names(train_class)&lt;-class
  head(train_class,5)
</code></pre>

<pre><code>##   A B C D E
## 1 1 0 0 0 0
## 2 1 0 0 0 0
## 3 1 0 0 0 0
## 4 1 0 0 0 0
## 5 1 0 0 0 0
</code></pre>

<p>The amount of predictors for the models are 52, in these was considered all the information provided from the arms, belt, dumbbell and forearms, for this was necessary removed the predictors that not contain information for all the registers like amplitude and others.</p>

<h2>DESCRIPTION OF THE MODELS</h2>

<h3>Linear Discriminant Analysis</h3>

<p>The first model considered is a linear discriminant analysis because the assumption of normality for each predictor is an approach that made easier the estimation of the parameters.</p>

<p>For measure the accuracy is used cross validation with 10 k-folds (this is the number for default in the function trainControl).</p>

<pre><code class="r">ctrl &lt;- trainControl(method = &quot;cv&quot;) 
model_lda&lt;-train(train$classe~.,method=&quot;lda&quot;,trControl=ctrl,data=train2)
</code></pre>

<pre><code>## Loading required package: MASS
</code></pre>

<pre><code class="r">model_lda
</code></pre>

<pre><code>## Linear Discriminant Analysis 
## 
## 9812 samples
##   51 predictors
##    5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## 
## Summary of sample sizes: 8832, 8831, 8832, 8829, 8831, 8831, ... 
## 
## Resampling results
## 
##   Accuracy  Kappa  Accuracy SD  Kappa SD
##   0.7       0.6    0.01         0.02    
## 
## 
</code></pre>

<p>The accuracy of the model is calculated in the following way:</p>

<pre><code class="r">pred_lda&lt;-predict(model_lda,test2)
table_lda&lt;-table(pred_lda,test$classe)
acc_lda&lt;-sum(diag(table_lda))/(sum(apply(table_lda,2,sum)))
acc_classes&lt;-diag(table_lda)/(apply(table_lda,2,sum))

#Table of results
table_lda
</code></pre>

<pre><code>##         
## pred_lda    A    B    C    D    E
##        A 2278  293  161  105   74
##        B   67 1191  170   68  289
##        C  209  240 1103  191  168
##        D  226   73  234 1168  191
##        E   10  101   43   76 1081
</code></pre>

<pre><code class="r">#Accuracy of the model
acc_lda
</code></pre>

<pre><code>## [1] 0.6953
</code></pre>

<pre><code class="r">#Accuracy for A,B,C,D and E respectly
acc_classes
</code></pre>

<pre><code>##      A      B      C      D      E 
## 0.8165 0.6275 0.6447 0.7264 0.5996
</code></pre>

<h3>Logistic Regression</h3>

<p>For the logistics regression is necessary fit a model for each of the response, this mean a model for the classes A,B,C,D and E, for doing that, was used the dataframe train_class into a loop and was calculated the probability P(Y=1|X) for each class within his respective model.</p>

<pre><code class="r">  probs&lt;-list()
  for (ñ in 1:5){
  model_glm&lt;-glm(train_class[,ñ]~.,family=binomial,data=train2)
  probs[[ñ]]&lt;-predict(model_glm,test2,type=&quot;response&quot;)
  }
</code></pre>

<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
</code></pre>

<pre><code class="r">  probs&lt;-as.data.frame(probs)
  names(probs)&lt;-class
</code></pre>

<p>For testing the model in the test set, the predicted response is the class with the hightest probability.</p>

<pre><code class="r">pred&lt;-vector()
for (w in 1:nrow(test2)){
  #Select the class for the hightest probability in each row: 
  pred[w]&lt;-names(probs)[which.max(probs[w,])] 
}
</code></pre>

<p>The accuracy is obtained creating a table between the predicted and test classes:</p>

<pre><code class="r">  table_glm&lt;-table(pred,test$classe)
  acc_glm&lt;-sum(diag(table_glm))/(sum(apply(table_glm,2,sum)))
  acc_classes_glm&lt;-diag(table_glm)/(apply(table_glm,2,sum))

  #Table of results
  table_glm
</code></pre>

<pre><code>##     
## pred    A    B    C    D    E
##    A 2428  260  190  123   93
##    B   61 1210  166   55  228
##    C  135  188 1145  174   99
##    D  142   65  134 1160  173
##    E   24  175   76   96 1210
</code></pre>

<pre><code class="r">  #Accuracy of the model
  acc_glm
</code></pre>

<pre><code>## [1] 0.7292
</code></pre>

<pre><code class="r">  #Accuracy for A,B,C,D and E respectly
  acc_classes_glm
</code></pre>

<pre><code>##      A      B      C      D      E 
## 0.8703 0.6375 0.6692 0.7214 0.6711
</code></pre>

<h2>RESULTS</h2>

<p>The linear discriminant analysis have an approximate accuracy of 70% in the cross validation and the test set, the prediction accuracy for the classes A,B,C,D and E are 82%,63%,64%,73% and 60%, respectively.</p>

<p>The logistic regression model have an  approximate accuracy of 73%, the prediction accuracy  for the classes A,B,C,D and E are 87%,64%,67%,72% and 67%, respectively. </p>

<p>According with the results presented above, the model selected for predict the twenty test set is the logistics regression because his accuracy is greater than the linear discriminant analysis.</p>

<h2>PREDICTION</h2>

<p>For the prediction of the twenty cases supplied by the course is necessary doing the following steps:</p>

<ul>
<li>Load the test set with the twenty cases: </li>
</ul>

<pre><code class="r">test_final=read.csv(file=&quot;pml-testing.csv&quot;,header=TRUE)
</code></pre>

<ul>
<li>Estimate the probabilities P(Y=1|X) for each class of the test set</li>
</ul>

<pre><code class="r">  probs_final&lt;-list()  
  for (ñ in 1:5){
  model_glm&lt;-glm(train_class[,ñ]~.,family=binomial,data=train2)
  probs_final[[ñ]]&lt;-predict(model_glm,test_final,type=&quot;response&quot;)
  }
</code></pre>

<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
</code></pre>

<pre><code class="r">probs_final&lt;-as.data.frame(probs_final)
names(probs_final)&lt;-class
</code></pre>

<p>-Finally are selected the classes with the hightest probability in each row of the dataframe probs_final.</p>

<pre><code class="r">pred_final&lt;-vector()
for (w in 1:nrow(test_final)){
   pred_final[w]&lt;-names(probs_final)[which.max(probs_final[w,])]}
</code></pre>

<p>The prediction for the twenty cases supplied by the course of practical machine learning are:</p>

<pre><code class="r">pred_final
</code></pre>

<pre><code>##  [1] &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;E&quot; &quot;D&quot; &quot;E&quot; &quot;A&quot; &quot;A&quot; &quot;D&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;E&quot; &quot;A&quot; &quot;A&quot;
## [18] &quot;B&quot; &quot;B&quot; &quot;B&quot;
</code></pre>

<h2>Testing the result</h2>

<p>Presenting the results in the platform of the course practical machine learning, of the twenty predicted classes sixteen was correct and four was incorrect. For give a solution to that, was considered a different approach for the wrong predictions, that is, consider the predicted class with the second highest probability, as follow:</p>

<ul>
<li>First is consider the probabilities of the problems with the id 8,11,12 and 16, cause this are the wrong predictions.</li>
</ul>

<pre><code class="r">wrong_pred&lt;-c(8,11,12,16)
</code></pre>

<p>-Second the rows of probs_second are sort in decreasing order and was selected the name of the column corresponding to the second index in the list.  </p>

<pre><code class="r">for (w in wrong_pred){
  sort_probs&lt;-sort(probs_final[w,],decreasing=TRUE,index.return=TRUE)
  #predict the class with the second hightest probability:
  pred_final[w]&lt;-names(sort_probs)[2]}
</code></pre>

<p>The new predict values for this cases are:</p>

<pre><code class="r">pred_final[wrong_pred]
</code></pre>

<pre><code>## [1] &quot;B&quot; &quot;B&quot; &quot;C&quot; &quot;E&quot;
</code></pre>

<p>Presenting these results in the platform of the course we found that the new values are correct, finally the predicted values for the twenty test are:</p>

<pre><code class="r">pred_final
</code></pre>

<pre><code>##  [1] &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;E&quot; &quot;D&quot; &quot;B&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot; &quot;E&quot; &quot;E&quot; &quot;A&quot;
## [18] &quot;B&quot; &quot;B&quot; &quot;B&quot;
</code></pre>

<h2>REFERENCES</h2>

<p>[1] Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human &#39;13) . Stuttgart, Germany: ACM SIGCHI, 2013.</p>

</body>

</html>

